
    DAOnboarding

    Onboarding StudyResearchers:  , Mr. Nobody, and @Lia Godoy PurposeAs DAOs become more popular and attract new people to contribute to their missions, a set of challenges must be addressed in order for DAOs to scale. One of the main issues is the onboarding process for new members, as it is common for people trying to contribute -or even sneak peeking to get a sense of what a DAO does- to feel overwhelmed by the amount of disperse information they find. This creates a barrier for new members to discover their place inside DAOs because they cannot find projects where they can add value or they may feel scared that they donâ€™t have the necessary skills to contribute.Different DAOs try to solve this in many ways and we can find articles and twitter threads explaining some of the leaders experiences about best practices for onboarding new contributors. Although this is good, there is no systematic review about onboarding processes in DAOs to identify best practices or what tools and strategies may benefit different DAOs.We see this as an opportunity to conduct a multi-phase study to survey the DAO onboarding landscape, so we can (1) offer a repository of onboarding strategies, (2) identify best practices and (3) understand different users motivations and actions inside DAOs (user personas). The main goal is to offer to the broader DAO community valuable resources for addressing their particular needs when it comes to onboard new members.Goals and Key-OutcomesDAO Onboarding practices articleDAO Onboarding practices repositoryCustom feedback on DAO practices for participating DAOsDAO User personasDAO Onboarding workshopStatusPhase 1: Consolidating helpful resources Phase 2: Literature review Phase 3: Mirror publicationPhase 4: Qualitative research, interviews, and self-onboardingsPhase 5: Analysis, production of journey maps and DAO user personasPhase 6: Initial findings and community feedbackPhase 7: Conclusions reportedPhase 8: Draft nÂ°1Phase 9: Draft nÂ°XPhase 10: Final publication in the Journal of Decentralized WorkPhase 11: DAO feedbackProject SpecsResearch Questions:What is DAO onboarding?What is the scope of DAO onboarding?How do we define onboarding effectiveness?What are various initial onboarding practices?Who are the people being onboarded to DAOs?How does onboarding contribute to an overall DAO career path?Study DesignPart 1: Onboarding LandscapeWe start by consolidating and reviewing existing resources about onboarding and DAO specific onboarding practices.Then we aim to map the current onboarding landscape by interviewing DAO contributors and newly onboarded members to analyze and systematize their onboarding practices, documenting their experiences and producing DAO onboarding review products like: a DAOnboarding article, onboarding practices repository, and DAO user personas.Â  Weâ€™ll also try to get ourselves onboarded onto as many DAOs as possible to get a sense of that process first hand, so we can complement the above research strategy.Part 2: Cohort StudyAfter mapping out the landscape, we take a deep dive through ethnography studies by following onboarding cohorts from selected DAOs. We observe what happens during their onboarding journey and how it affects their onboarding outcome. This allows us to overcome survivor bias, observing not just the people visible to the process but also the people who silently dropped out.Part 3: DAOnboarding coaching and workshop developmentUpon completion of phase one and two, a three day workshop will be developed in order to disseminate insights identified from the interview and cohort studies. Community leaders and talent coordinators responsible for onboarding. The workshop will cover best practices for onboarding programs and everyone is invited to participate. The three day workshop will be recorded with a standalone curriculum available for download.Part 4: SimulationWe create an agent-based model of the onboarding process, with simulated events and outcomes. Decentralized communities are complex social systems which can be studied using agent-based modeling methods. Using simulation techniques it is possible to test different governance strategies and tokenomic models before deployment. The implications of this technology provide a scenario modeler to test which onboarding models work best for your community given a set of common parameters.FAQHow will this study be funded or supported?How will we define leadership or decentralized leadership for this study?What will the criteria for recruitment be for the study?What data will be collected from participants? How will these data be stored and protected?What are the benefits (or compensation) to participants?What are the benefits to participating organizations or society at large?What are the risks or threats to participants?What are the risks or threats to participating organizations?What steps will be taken to minimize risks or threats?ResourcesCurrently, resources have been randomly shared throughout the Discord server (all-things-DAO, onboarding, general-on-topic).Resources need to be consolidated organized, reviewed, and prioritized for both talentDAO and the broader DAO community.Phase 2: Rapid reviewAs the first step of our research we conduct a rapid review of the available onboarding literature (secondary research). A rapid review aims to answer clearly defined questions with the best available evidence defined through explicit criteria. These include:Scholarly journals, peer-reviewedAvailable through ABI/INFORM Global, Business Source Premier, PsychINFO databasesLimited to meta-analyses and systematic reviewsArticles published in EnglishMeta-analyses and systematic reviews synthesize the whole body of research on a topic up to a specific date. Starting from this type of publication ensures we leverage available valid knowledge on the topic of onboarding to inform (primary) quali-quantitative field research within DAOs. Data extraction From each study we report in the form of a clearly structured table [for reference see matrix for meta-analyses and systematic reviews for #decentralized-leadership] any information relevant to the rapid review questions, such as year of publication, research design, sample size, population (e.g., industry, type of employees), outcome measures, possible moderators or mediators, main findings, effect sizes with a 95% confidence interval, limitations.Guidelines on Effect sizesAn outcome can be statistically significant but not practically relevant. Even a trivial effect can be statistically significant if the sample size is large. Contrarily, even a large, practical relevant effect can be statistically non-significant if the sample size is small. Also, p-values do NOT measure the probability that the studied hypothesis is true, or the probability that the data were produced by random chance alone (Ziliak, 2016). Nor can a p-value tell you the size of an effect, the strength of the evidence or the importance of a result. For this reason, instead of assessing p-values we look at â€˜effect sizeâ€™ â€“ a standard measure of the magnitude of the effect â€“ of the studies included when addressing impact questions.To determine the magnitude of an effect, apply Cohenâ€™s rules of thumb (Cohen, 1988; see below). According to Cohen a â€˜smallâ€™ effect is an effect that is only visible through careful examination. A â€˜mediumâ€™ effect, however, is one that is â€˜visible to the naked eye of the careful observerâ€™. Finally, a â€˜largeâ€™ effect is one that anybody can easily see because it is substantial.                       Source: CEBMa Guidelines for REAs in Management and OrganizationsLINKS ðŸ”—Grant ProposalBrainstorming NotesMystery Shopper FrameworkOnline ResourcesMeeting Notes